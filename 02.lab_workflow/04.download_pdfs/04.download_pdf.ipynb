{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56043dc9-597f-46c5-a68a-c18368c20b43",
   "metadata": {},
   "source": [
    "# Download PDFs for Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0e29ad-c7a7-431c-9388-a997e6a1dbfd",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57aa2d10-445c-4f0d-8382-5c01f5eb534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, time, requests\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# === CONFIG ===\n",
    "CONTACT_EMAIL = \"ebuchanan@harrisburgu.edu\"   # <- REQUIRED for Unpaywall; use a real email\n",
    "INPUT_CSV = \"../03.classify_data/classified_lab.csv\"  # or wherever your df lives\n",
    "DOI_COL = \"doi\"\n",
    "OUT_DIR = Path(\"pdfs\")\n",
    "POLITE_DELAY = 0.3               # seconds between network calls\n",
    "\n",
    "# === Helpers ===\n",
    "HEADERS_JSON = {\"Accept\": \"application/json\", \"User-Agent\": f\"LAB-pdf-fetcher ({CONTACT_EMAIL})\"}\n",
    "HEADERS_ANY  = {\"User-Agent\": f\"LAB-pdf-fetcher ({CONTACT_EMAIL})\"}\n",
    "\n",
    "def clean_doi(doi: str) -> str:\n",
    "    if not isinstance(doi, str): return \"\"\n",
    "    doi = doi.strip()\n",
    "    doi = re.sub(r\"^https?://(dx\\.)?doi\\.org/\", \"\", doi, flags=re.I)\n",
    "    return doi\n",
    "\n",
    "def safe_get(url, params=None, headers=None, timeout=30, stream=False, allow_redirects=True):\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=timeout, stream=stream, allow_redirects=allow_redirects)\n",
    "        r.raise_for_status()\n",
    "        return r, None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def find_pdf_via_unpaywall(doi: str):\n",
    "    # https://api.unpaywall.org/v2/{doi}?email=...\n",
    "    url = f\"https://api.unpaywall.org/v2/{doi}\"\n",
    "    r, err = safe_get(url, params={\"email\": CONTACT_EMAIL}, headers=HEADERS_JSON)\n",
    "    if err or not r.ok:\n",
    "        return None, f\"unpaywall err: {err or r.status_code}\"\n",
    "    js = r.json()\n",
    "    # best_oa_location.url_for_pdf or any oa_location url_for_pdf\n",
    "    cand = (js.get(\"best_oa_location\") or {}).get(\"url_for_pdf\")\n",
    "    if not cand:\n",
    "        for loc in js.get(\"oa_locations\") or []:\n",
    "            if loc.get(\"url_for_pdf\"): \n",
    "                cand = loc[\"url_for_pdf\"]; \n",
    "                break\n",
    "    return cand, None\n",
    "\n",
    "def find_pdf_via_openalex(doi: str):\n",
    "    # https://api.openalex.org/works/DOI:{doi}?select=best_oa_location,primary_location,open_access\n",
    "    url = f\"https://api.openalex.org/works/DOI:{doi}\"\n",
    "    r, err = safe_get(url, params={\"select\":\"best_oa_location,primary_location,open_access\"}, headers=HEADERS_JSON)\n",
    "    if err or not r.ok:\n",
    "        return None, f\"openalex err: {err or r.status_code}\"\n",
    "    js = r.json()\n",
    "    # try best_oa_location.pdf_url, then primary_location.pdf_url, then open_access.oa_url (may be landing page)\n",
    "    for key in (\"best_oa_location\",\"primary_location\"):\n",
    "        loc = js.get(key) or {}\n",
    "        if isinstance(loc, dict) and loc.get(\"pdf_url\"):\n",
    "            return loc[\"pdf_url\"], None\n",
    "    oa = js.get(\"open_access\") or {}\n",
    "    if oa.get(\"oa_url\") and oa[\"oa_url\"].lower().endswith(\".pdf\"):\n",
    "        return oa[\"oa_url\"], None\n",
    "    return None, None\n",
    "\n",
    "def find_pdf_via_crossref(doi: str):\n",
    "    # https://api.crossref.org/works/{doi} -> message.link[] where content-type==application/pdf\n",
    "    url = f\"https://api.crossref.org/works/{doi}\"\n",
    "    r, err = safe_get(url, headers=HEADERS_JSON)\n",
    "    if err or not r.ok:\n",
    "        return None, f\"crossref err: {err or r.status_code}\"\n",
    "    msg = r.json().get(\"message\", {})\n",
    "    for link in msg.get(\"link\", []) or []:\n",
    "        if (link.get(\"content-type\") or \"\").lower() == \"application/pdf\" and link.get(\"URL\"):\n",
    "            return link[\"URL\"], None\n",
    "    return None, None\n",
    "\n",
    "def resolve_doi_to_pdf(doi: str):\n",
    "    # Follow DOI redirect; if final response is a PDF, accept it\n",
    "    url = f\"https://doi.org/{doi}\"\n",
    "    r, err = safe_get(url, headers=HEADERS_ANY, timeout=30, stream=True, allow_redirects=True)\n",
    "    if err or not r:\n",
    "        return None, f\"doi resolve err: {err}\"\n",
    "    # If headers say it's a PDF, use the final URL\n",
    "    ctype = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "    final_url = r.url\n",
    "    if \"application/pdf\" in ctype or final_url.lower().endswith(\".pdf\"):\n",
    "        # We'll re-download with non-stream to get full content\n",
    "        return final_url, None\n",
    "    return None, None\n",
    "\n",
    "def download_pdf(pdf_url: str, out_path: Path):\n",
    "    r, err = safe_get(pdf_url, headers=HEADERS_ANY, stream=True, timeout=60)\n",
    "    if err or not r:\n",
    "        return False, f\"download err: {err or 'unknown'}\"\n",
    "    ctype = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "    if \"application/pdf\" not in ctype and not pdf_url.lower().endswith(\".pdf\"):\n",
    "        # Some servers misreport; try anyway if content starts with %PDF\n",
    "        chunk = next(r.iter_content(chunk_size=5*1024), b\"\")\n",
    "        if not chunk.startswith(b\"%PDF\"):\n",
    "            return False, f\"not pdf (ctype={ctype})\"\n",
    "        # If it is PDF, write first chunk + rest\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(chunk)\n",
    "            for chunk in r.iter_content(chunk_size=64*1024):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "        return True, None\n",
    "    # Normal path\n",
    "    with open(out_path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=64*1024):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "    return True, None\n",
    "\n",
    "def safe_filename_from_doi(doi: str) -> str:\n",
    "    # turn 10.1234/abc.def -> 10.1234_abc.def.pdf\n",
    "    return re.sub(r\"[^A-Za-z0-9._-]+\", \"_\", doi) + \".pdf\"\n",
    "\n",
    "def fetch_pdf_for_doi(doi: str, out_dir: Path = OUT_DIR):\n",
    "    doi = clean_doi(doi)\n",
    "    if not doi:\n",
    "        return \"skip\", \"no-doi\", None\n",
    "    steps = [\n",
    "        (\"unpaywall\", find_pdf_via_unpaywall),\n",
    "        (\"openalex\",  find_pdf_via_openalex),\n",
    "        (\"crossref\",  find_pdf_via_crossref),\n",
    "        (\"resolve\",   resolve_doi_to_pdf),\n",
    "    ]\n",
    "    pdf_url = None\n",
    "    notes = []\n",
    "    for name, func in steps:\n",
    "        url, err = func(doi)\n",
    "        if url:\n",
    "            pdf_url = url\n",
    "            source = name\n",
    "            break\n",
    "        if err:\n",
    "            notes.append(f\"{name}:{err}\")\n",
    "        time.sleep(POLITE_DELAY)\n",
    "    if not pdf_url:\n",
    "        return \"miss\", \"; \".join(notes) or \"no-pdf-found\", None\n",
    "\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fname = safe_filename_from_doi(doi)\n",
    "    out_path = out_dir / fname\n",
    "    ok, derr = download_pdf(pdf_url, out_path)\n",
    "    if not ok:\n",
    "        return \"fail\", f\"{source} -> {derr}\", pdf_url\n",
    "    return \"ok\", source, str(out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14262bb8-2cca-4cac-b080-d1ce48e2a66e",
   "metadata": {},
   "source": [
    "## Attempt Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc23904a-7957-468c-84b2-edb6b060fb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>venue</th>\n",
       "      <th>authors</th>\n",
       "      <th>abstract</th>\n",
       "      <th>keywords</th>\n",
       "      <th>openalex_id</th>\n",
       "      <th>is_oa</th>\n",
       "      <th>cited_by</th>\n",
       "      <th>doi_clean</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Flickr frequency norms: What 17 years of i...</td>\n",
       "      <td>2022</td>\n",
       "      <td>10.3758/s13428-022-02031-y</td>\n",
       "      <td>Behavior Research Methods</td>\n",
       "      <td>Marco A. Petilli; Fritz Günther; Marco Marelli</td>\n",
       "      <td>Word frequency is one of the best predictors o...</td>\n",
       "      <td>['Computer science', 'Natural language process...</td>\n",
       "      <td>https://openalex.org/W4311282624</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>10.3758/s13428-022-02031-y</td>\n",
       "      <td>computer science natural language processing i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Translation norms for Malay and English words:...</td>\n",
       "      <td>2022</td>\n",
       "      <td>10.3758/s13428-022-01977-3</td>\n",
       "      <td>Behavior Research Methods</td>\n",
       "      <td>Soon Tat Lee; Walter J. B. van Heuven; Jessica...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Malay', 'Linguistics', 'Ambiguity', 'Compute...</td>\n",
       "      <td>https://openalex.org/W4304196404</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>10.3758/s13428-022-01977-3</td>\n",
       "      <td>malay linguistics ambiguity computer science v...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Flickr frequency norms: what 17 years of i...</td>\n",
       "      <td>2022</td>\n",
       "      <td>10.31234/osf.io/h4q86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marco A. Petilli; Fritz Guenther; Marco Marelli</td>\n",
       "      <td>Word frequency is one of the best predictors o...</td>\n",
       "      <td>['Word lists by frequency', 'Computer science'...</td>\n",
       "      <td>https://openalex.org/W4283711714</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10.31234/osf.io/h4q86</td>\n",
       "      <td>word lists frequency computer science natural ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Lancaster Sensorimotor Norms: multidimensi...</td>\n",
       "      <td>2019</td>\n",
       "      <td>10.3758/s13428-019-01316-z</td>\n",
       "      <td>Behavior Research Methods</td>\n",
       "      <td>Dermot Lynott; Louise Connell; Marc Brysbaert;...</td>\n",
       "      <td>Abstract Sensorimotor information plays a fund...</td>\n",
       "      <td>['Cognitive psychology', 'Psychology', 'Percep...</td>\n",
       "      <td>https://openalex.org/W2982116886</td>\n",
       "      <td>True</td>\n",
       "      <td>307</td>\n",
       "      <td>10.3758/s13428-019-01316-z</td>\n",
       "      <td>cognitive psychology psychology perception cog...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As designações para o pão nosso de cada dia: a...</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.17851/2237-2083.29.1.533-588</td>\n",
       "      <td>Revista de Estudos da Linguagem</td>\n",
       "      <td>Vanessa Yida</td>\n",
       "      <td>Este artigo tem como proposta a identificação ...</td>\n",
       "      <td>['Lexico', 'Linguistics', 'Humanities', 'Art',...</td>\n",
       "      <td>https://openalex.org/W3095649193</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>10.17851/2237-2083.29.1.533-588</td>\n",
       "      <td>lexico linguistics humanities art lexicon phil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  year  \\\n",
       "0  The Flickr frequency norms: What 17 years of i...  2022   \n",
       "1  Translation norms for Malay and English words:...  2022   \n",
       "2  The Flickr frequency norms: what 17 years of i...  2022   \n",
       "3  The Lancaster Sensorimotor Norms: multidimensi...  2019   \n",
       "4  As designações para o pão nosso de cada dia: a...  2021   \n",
       "\n",
       "                               doi                            venue  \\\n",
       "0       10.3758/s13428-022-02031-y        Behavior Research Methods   \n",
       "1       10.3758/s13428-022-01977-3        Behavior Research Methods   \n",
       "2            10.31234/osf.io/h4q86                              NaN   \n",
       "3       10.3758/s13428-019-01316-z        Behavior Research Methods   \n",
       "4  10.17851/2237-2083.29.1.533-588  Revista de Estudos da Linguagem   \n",
       "\n",
       "                                             authors  \\\n",
       "0     Marco A. Petilli; Fritz Günther; Marco Marelli   \n",
       "1  Soon Tat Lee; Walter J. B. van Heuven; Jessica...   \n",
       "2    Marco A. Petilli; Fritz Guenther; Marco Marelli   \n",
       "3  Dermot Lynott; Louise Connell; Marc Brysbaert;...   \n",
       "4                                       Vanessa Yida   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Word frequency is one of the best predictors o...   \n",
       "1                                                NaN   \n",
       "2  Word frequency is one of the best predictors o...   \n",
       "3  Abstract Sensorimotor information plays a fund...   \n",
       "4  Este artigo tem como proposta a identificação ...   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  ['Computer science', 'Natural language process...   \n",
       "1  ['Malay', 'Linguistics', 'Ambiguity', 'Compute...   \n",
       "2  ['Word lists by frequency', 'Computer science'...   \n",
       "3  ['Cognitive psychology', 'Psychology', 'Percep...   \n",
       "4  ['Lexico', 'Linguistics', 'Humanities', 'Art',...   \n",
       "\n",
       "                        openalex_id  is_oa  cited_by  \\\n",
       "0  https://openalex.org/W4311282624   True         8   \n",
       "1  https://openalex.org/W4304196404   True         7   \n",
       "2  https://openalex.org/W4283711714   True         1   \n",
       "3  https://openalex.org/W2982116886   True       307   \n",
       "4  https://openalex.org/W3095649193   True         1   \n",
       "\n",
       "                         doi_clean  \\\n",
       "0       10.3758/s13428-022-02031-y   \n",
       "1       10.3758/s13428-022-01977-3   \n",
       "2            10.31234/osf.io/h4q86   \n",
       "3       10.3758/s13428-019-01316-z   \n",
       "4  10.17851/2237-2083.29.1.533-588   \n",
       "\n",
       "                                                text  class  \n",
       "0  computer science natural language processing i...      1  \n",
       "1  malay linguistics ambiguity computer science v...      1  \n",
       "2  word lists frequency computer science natural ...      1  \n",
       "3  cognitive psychology psychology perception cog...      1  \n",
       "4  lexico linguistics humanities art lexicon phil...      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Run over your dataframe ===\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e0baab-cd92-4226-ac50-73e2f3b7df85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] OK  | 10.3758/s13428-022-02031-y -> pdfs/10.3758_s13428-022-02031-y.pdf\n",
      "[1] OK  | 10.3758/s13428-022-01977-3 -> pdfs/10.3758_s13428-022-01977-3.pdf\n",
      "[2] OK  | 10.31234/osf.io/h4q86 -> pdfs/10.31234_osf.io_h4q86.pdf\n",
      "[3] OK  | 10.3758/s13428-019-01316-z -> pdfs/10.3758_s13428-019-01316-z.pdf\n",
      "[4] OK  | 10.17851/2237-2083.29.1.533-588 -> pdfs/10.17851_2237-2083.29.1.533-588.pdf\n",
      "[5] OK  | 10.1371/journal.pone.0211336 -> pdfs/10.1371_journal.pone.0211336.pdf\n",
      "[6] OK  | 10.3758/s13428-022-01923-3 -> pdfs/10.3758_s13428-022-01923-3.pdf\n",
      "[7] OK  | 10.3758/s13428-022-01810-x -> pdfs/10.3758_s13428-022-01810-x.pdf\n",
      "[8] OK  | 10.3389/fpsyg.2019.00278 -> pdfs/10.3389_fpsyg.2019.00278.pdf\n",
      "[9] MISS| 10.1055/s-0039-3400972 -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1055/s-0039-3400972?select=best_oa_location%2Cprimary_location%2Copen_access\n",
      "[10] OK  | 10.3758/s13428-023-02198-y -> pdfs/10.3758_s13428-023-02198-y.pdf\n",
      "[11] MISS| 10.1044/2018_ajslp-17-0131 -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1044/2018_ajslp-17-0131?select=best_oa_location%2Cprimary_location%2Copen_access; resolve:doi resolve err: 403 Client Error: Forbidden for url: http://pubs.asha.org/doi/10.1044/2018_AJSLP-17-0131\n",
      "[12] MISS| 10.31234/osf.io/ktjwp -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.31234/osf.io/ktjwp?select=best_oa_location%2Cprimary_location%2Copen_access\n",
      "[13] FAIL| 10.1177/01427237251336497 -> crossref -> download err: 403 Client Error: Forbidden for url: https://journals.sagepub.com/doi/pdf/10.1177/01427237251336497 (url=https://journals.sagepub.com/doi/pdf/10.1177/01427237251336497)\n",
      "[14] OK  | 10.1057/s41599-021-00836-4 -> pdfs/10.1057_s41599-021-00836-4.pdf\n",
      "[15] OK  | 10.3758/s13428-022-01790-y -> pdfs/10.3758_s13428-022-01790-y.pdf\n",
      "[16] MISS| 10.1080/02687038.2021.1923947 -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1080/02687038.2021.1923947?select=best_oa_location%2Cprimary_location%2Copen_access; resolve:doi resolve err: 403 Client Error: Forbidden for url: https://www.tandfonline.com/doi/full/10.1080/02687038.2021.1923947\n",
      "[17] OK  | 10.1371/journal.pone.0209524 -> pdfs/10.1371_journal.pone.0209524.pdf\n",
      "[18] MISS| 10.1044/2020_ajslp-19-00176 -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1044/2020_ajslp-19-00176?select=best_oa_location%2Cprimary_location%2Copen_access; resolve:doi resolve err: 403 Client Error: Forbidden for url: http://pubs.asha.org/doi/10.1044/2020_AJSLP-19-00176\n",
      "[19] OK  | 10.3758/s13428-021-01787-z -> pdfs/10.3758_s13428-021-01787-z.pdf\n",
      "[20] MISS| 10.1080/07268602.2018.1510727 -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1080/07268602.2018.1510727?select=best_oa_location%2Cprimary_location%2Copen_access; resolve:doi resolve err: 403 Client Error: Forbidden for url: https://www.tandfonline.com/doi/full/10.1080/07268602.2018.1510727\n",
      "[21] MISS| 10.1075/scl.86.09mor -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1075/scl.86.09mor?select=best_oa_location%2Cprimary_location%2Copen_access\n",
      "[22] MISS| 10.1016/j.jfludis.2023.105988 -> openalex:openalex err: 404 Client Error: NOT FOUND for url: https://api.openalex.org/works/DOI:10.1016/j.jfludis.2023.105988?select=best_oa_location%2Cprimary_location%2Copen_access\n",
      "[23] OK  | 10.3758/s13428-022-01928-y -> pdfs/10.3758_s13428-022-01928-y.pdf\n",
      "[24] OK  | 10.12688/openreseurope.15380.3 -> pdfs/10.12688_openreseurope.15380.3.pdf\n"
     ]
    }
   ],
   "source": [
    "if DOI_COL not in df.columns:\n",
    "    raise ValueError(f\"Column '{DOI_COL}' not found in {INPUT_CSV}\")\n",
    "\n",
    "results = []\n",
    "for i, doi in enumerate(df[DOI_COL].astype(str)):\n",
    "    status, info, path_or_url = fetch_pdf_for_doi(doi)\n",
    "    if status == \"ok\":\n",
    "        print(f\"[{i}] OK  | {doi} -> {path_or_url}\")\n",
    "    elif status == \"miss\":\n",
    "        print(f\"[{i}] MISS| {doi} -> {info}\")\n",
    "    elif status == \"fail\":\n",
    "        print(f\"[{i}] FAIL| {doi} -> {info} (url={path_or_url})\")\n",
    "    elif status == \"skip\":\n",
    "        print(f\"[{i}] SKIP| {doi} -> {info}\")\n",
    "    results.append((status, info, path_or_url))\n",
    "    time.sleep(POLITE_DELAY)\n",
    "\n",
    "# Optional: attach results back to the dataframe for your own bookkeeping (not required)\n",
    "df[\"pdf_status\"] = [r[0] for r in results]\n",
    "df[\"pdf_note\"]   = [r[1] for r in results]\n",
    "df[\"pdf_path\"]   = [r[2] for r in results]\n",
    "df.to_csv(\"with_pdf_status.csv\", index=False)\n",
    "print(\"Wrote status file -> with_pdf_status.csv\")\n",
    "print(f\"PDFs saved in: {OUT_DIR.resolve()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Jupyter Env)",
   "language": "python",
   "name": "py311-jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
