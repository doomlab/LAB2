{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe type is: <class 'pandas.core.frame.DataFrame'>\n",
      "Dataframe shape is: (2146, 2)\n",
      "Columns in data frame are: Index(['code', 'Text'], dtype='object')\n",
      "Missing values in Dataframe are: code    0\n",
      "Text    0\n",
      "dtype: int64\n",
      "  code                                               Text\n",
      "0   No  â€šÃ„Ãºsoundâ€šÃ„Ã¹ alternatives to visual gra...\n",
      "1   No  1980 dec usersâ€šÃ„Ã´ group report The 1980 me...\n"
     ]
    }
   ],
   "source": [
    "#Excel pre-processing--\n",
    "#Column TITLE,ABSTRACT,KEYWORDS are conatenated together separating by space,using & statement \n",
    "#ABSTRACT FILTERED BY 'NA' and corresponding rows are deleted.\n",
    "#special character Â which occurs in KEYWORDS is replace by a space\n",
    "\n",
    "\n",
    "import csv\n",
    "import pandas as pd \n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer, WordNetLemmatizer\n",
    "df=pd.read_csv('train_data2.csv',encoding='utf-8')\n",
    "df_pd = pd.DataFrame(df)\n",
    "print('Dataframe type is:',type(df))\n",
    "print('Dataframe shape is:',df.shape)\n",
    "print('Columns in data frame are:',df.columns)\n",
    "print('Missing values in Dataframe are:',df.isnull().sum())\n",
    "print(df[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  code                                               Text\n",
      "0   No  sound alternatives to visual graphics for expl...\n",
      "  code                                               Text\n",
      "0   No  â€šÃ„Ãºsoundâ€šÃ„Ã¹ alternatives to visual gra...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_clean=df.copy()\n",
    "df_clean['Text'] = [re.sub('<.*?>', '', e) for e in df_clean['Text']] #remove HTML tags\n",
    "df_clean['Text'] =[re.sub(r'[^\\w\\s]', '', e) for e in df_clean['Text']]## remove punc\n",
    "df_clean['Text'] =[re.sub(r'\\d+', '', e) for e in df_clean['Text']]# remove numbers\n",
    "df_clean['Text']=[re.sub(r'[â€šÃÃº]?', '',e) for e in df_clean['Text'] ]# remove special character \n",
    "df_clean['Text']=[re.sub(r'[⁰¹²³⁴⁵⁶⁷⁸⁹]?', '',e) for e in df_clean['Text'] ]# remove superscript\n",
    "df_clean['Text']=[re.sub(r'NA', '',e) for e in df_clean['Text'] ]#remove 'NA' and replace by space\n",
    "df_clean['Text']=[re.sub(r'Â\\xa0', ' ',e) for e in df_clean['Text'] ] # remove Â\\xa0\n",
    "df_clean['Text']=df_clean['Text'].str.lower() # remove Â\\xa0\n",
    "\n",
    "\n",
    "print(df_clean[:1])\n",
    "print(df[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sound alternatives to visual graphics for exploratory data analysis efficient exploratory data analysis eda may be aided by succinct but informative graphical representations eg tukey plots that convey information about central tendency variability and shape of distributions and that permit detection of outliers using research strategies adapted from studies of crossmodal perceptual equivalence we show how auditory analogies of such displays may offer an effective alternative to visual plots for eda central tendency exploratory data analysis visual graphic auditory presentation auditory display ']\n"
     ]
    }
   ],
   "source": [
    "feature_extraction=df_clean.copy() # copying the dataframe\n",
    "\n",
    "feature_extraction1=feature_extraction.drop(['code'],axis=1)\n",
    "feature_extraction2=feature_extraction1['Text'].values.tolist()\n",
    "print(feature_extraction2[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization, lemmatization, \n",
    "###  Note: stemmer was causing  problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', \"'sound\", 'alternative', 'to', 'visual']\n"
     ]
    }
   ],
   "source": [
    "token=word_tokenize(str(feature_extraction2))\n",
    "token1=[w.lower() for w in token]# lower case\n",
    "#porter = nltk.PorterStemmer()\n",
    "#token2=[porter.stem(t) for t in token1]\n",
    "wnl = nltk.WordNetLemmatizer()\n",
    "token2= [wnl.lemmatize(t) for t in token1]\n",
    "print(token2[:5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove stopwords &  Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'sound\", 'alternative', 'visual', 'graphic', 'exploratory', 'data', 'analysis', 'efficient', 'exploratory', 'data']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "all_words_clean = []\n",
    "for word in token2:\n",
    "    if word not in stopwords.words('english') and word not in string.punctuation:\n",
    "        all_words_clean.append(word)\n",
    "print(all_words_clean[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of most common words, 100 words are chosen based on trail and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('word', 3219), ('language', 2767), ('study', 1707), ('research', 1686), ('science', 1602), ('data', 1325), ('analysis', 1272), ('wa', 1208), ('lexical', 1064), ('cognitive', 1045), ('norm', 1012), ('psychology', 997), ('database', 978), ('linguistic', 956), ('frequency', 942), ('article', 927), ('social', 898), ('method', 882), ('semantic', 856), ('processing', 839), ('result', 835), ('stimulus', 823), ('system', 794), ('used', 789), ('information', 788), ('task', 779), ('using', 766), ('two', 763), ('model', 757), ('english', 729), ('effect', 727), ('rating', 722), ('set', 719), ('linguistics', 712), ('present', 686), ('measure', 650), ('response', 642), ('learning', 635), ('ha', 627), ('also', 623)]\n"
     ]
    }
   ],
   "source": [
    "all_freq = nltk.FreqDist(w.lower() for w in all_words_clean)\n",
    "word_features= list(all_freq.most_common(100))\n",
    "word_features1=[x[0] for x in word_features]\n",
    "\n",
    "print (all_freq.most_common(40))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contains(word)': True, 'contains(language)': True, 'contains(study)': True, 'contains(research)': True, 'contains(science)': True, 'contains(data)': True, 'contains(analysis)': True, 'contains(wa)': True, 'contains(lexical)': True, 'contains(cognitive)': True, 'contains(norm)': True, 'contains(psychology)': True, 'contains(database)': True, 'contains(linguistic)': True, 'contains(frequency)': True, 'contains(article)': True, 'contains(social)': True, 'contains(method)': True, 'contains(semantic)': True, 'contains(processing)': True, 'contains(result)': True, 'contains(stimulus)': True, 'contains(system)': True, 'contains(used)': True, 'contains(information)': True, 'contains(task)': True, 'contains(using)': True, 'contains(two)': True, 'contains(model)': True, 'contains(english)': True, 'contains(effect)': True, 'contains(rating)': True, 'contains(set)': True, 'contains(linguistics)': True, 'contains(present)': True, 'contains(measure)': True, 'contains(response)': True, 'contains(learning)': True, 'contains(ha)': True, 'contains(also)': True, 'contains(speech)': True, 'contains(participant)': True, 'contains(different)': True, 'contains(time)': True, 'contains(experiment)': True, 'contains(test)': True, 'contains(use)': True, 'contains(one)': True, 'contains(memory)': True, 'contains(group)': True, 'contains(may)': True, 'contains(human)': True, 'contains(number)': True, 'contains(child)': True, 'contains(biology)': True, 'contains(age)': True, 'contains(visual)': True, 'contains(corpus)': True, 'contains(new)': True, 'contains(sentence)': True, 'contains(neuroscience)': True, 'contains(recognition)': True, 'contains(perception)': True, 'contains(text)': True, 'contains(difference)': True, 'contains(based)': True, 'contains(population)': True, 'contains(picture)': True, 'contains(reading)': True, 'contains(computer)': True, 'contains(behavior)': True, 'contains(process)': True, 'contains(variable)': True, 'contains(researcher)': True, 'contains(however)': True, 'contains(property)': True, 'contains(life)': True, 'contains(performance)': True, 'contains(object)': True, 'contains(category)': True, 'contains(well)': True, 'contains(available)': True, 'contains(feature)': True, 'contains(similarity)': True, 'contains(structure)': True, 'contains(meaning)': True, 'contains(chinese)': True, 'contains(network)': True, 'contains(first)': True, 'contains(health)': True, 'contains(show)': True, 'contains(acquisition)': True, 'contains(name)': True, 'contains(item)': True, 'contains(found)': True, 'contains(three)': True, 'contains(adult)': True, 'contains(brain)': True, 'contains(familiarity)': True, 'contains(technique)': True}\n"
     ]
    }
   ],
   "source": [
    "def document_features(document): # [_document-classify-extractor]\n",
    "    document_words = set(document) # [_document-classify-set]\n",
    "    features = {}\n",
    "    for word in word_features1:\n",
    "        features['contains({})'.format(word)] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "print(document_features(token2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=df_clean['Text'].values.tolist()\n",
    "token=[word_tokenize(str(x)) for x in list1]\n",
    "\n",
    "list2=df_clean['code'].values.tolist()\n",
    "labeled_df=list(zip(token,list2))\n",
    "labeled_df[:2]\n",
    "from random import shuffle \n",
    "shuffle(labeled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'contains(word)': False, 'contains(language)': True, 'contains(study)': False, 'contains(research)': True, 'contains(science)': True, 'contains(data)': False, 'contains(analysis)': True, 'contains(wa)': False, 'contains(lexical)': True, 'contains(cognitive)': True, 'contains(norm)': False, 'contains(psychology)': True, 'contains(database)': False, 'contains(linguistic)': False, 'contains(frequency)': False, 'contains(article)': True, 'contains(social)': True, 'contains(method)': False, 'contains(semantic)': False, 'contains(processing)': False, 'contains(result)': False, 'contains(stimulus)': False, 'contains(system)': False, 'contains(used)': True, 'contains(information)': True, 'contains(task)': False, 'contains(using)': False, 'contains(two)': True, 'contains(model)': False, 'contains(english)': True, 'contains(effect)': False, 'contains(rating)': False, 'contains(set)': False, 'contains(linguistics)': True, 'contains(present)': False, 'contains(measure)': False, 'contains(response)': False, 'contains(learning)': False, 'contains(ha)': False, 'contains(also)': False, 'contains(speech)': False, 'contains(participant)': False, 'contains(different)': True, 'contains(time)': False, 'contains(experiment)': False, 'contains(test)': False, 'contains(use)': False, 'contains(one)': False, 'contains(memory)': False, 'contains(group)': False, 'contains(may)': True, 'contains(human)': False, 'contains(number)': False, 'contains(child)': False, 'contains(biology)': True, 'contains(age)': False, 'contains(visual)': False, 'contains(corpus)': False, 'contains(new)': True, 'contains(sentence)': False, 'contains(neuroscience)': True, 'contains(recognition)': False, 'contains(perception)': False, 'contains(text)': False, 'contains(difference)': False, 'contains(based)': False, 'contains(population)': False, 'contains(picture)': False, 'contains(reading)': False, 'contains(computer)': True, 'contains(behavior)': False, 'contains(process)': False, 'contains(variable)': False, 'contains(researcher)': False, 'contains(however)': False, 'contains(property)': False, 'contains(life)': True, 'contains(performance)': False, 'contains(object)': False, 'contains(category)': False, 'contains(well)': False, 'contains(available)': False, 'contains(feature)': False, 'contains(similarity)': False, 'contains(structure)': False, 'contains(meaning)': False, 'contains(chinese)': False, 'contains(network)': True, 'contains(first)': False, 'contains(health)': True, 'contains(show)': False, 'contains(acquisition)': False, 'contains(name)': False, 'contains(item)': False, 'contains(found)': True, 'contains(three)': False, 'contains(adult)': False, 'contains(brain)': False, 'contains(familiarity)': False, 'contains(technique)': False}, 'No')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_set = [(document_features(doc), category) for (doc, category) in labeled_df]\n",
    "print (feature_set[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AND VALIDATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2146\n",
      "1746\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "print (len(feature_set)) # Output: \n",
    " \n",
    "validation_set = feature_set[:400]#Validation\n",
    "train_set = feature_set[400:]\n",
    " \n",
    "print (len(train_set)) # Output: \n",
    "print (len(validation_set)) # Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.815\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    " \n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "from nltk import classify \n",
    " \n",
    "accuracy = classify.accuracy(classifier, validation_set)\n",
    "print (accuracy) # Output: 0.365 len feture set 20#output 51% feature 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(biology) = True               No : Yes    =     68.0 : 1.0\n",
      "        contains(health) = True               No : Yes    =     34.7 : 1.0\n",
      "          contains(life) = True               No : Yes    =     22.1 : 1.0\n",
      "   contains(linguistics) = True               No : Yes    =     18.5 : 1.0\n",
      "   contains(familiarity) = True              Yes : No     =     17.3 : 1.0\n",
      "  contains(neuroscience) = True               No : Yes    =     14.1 : 1.0\n",
      "       contains(science) = True               No : Yes    =      9.8 : 1.0\n",
      "        contains(social) = True               No : Yes    =      8.9 : 1.0\n",
      "    contains(researcher) = True               No : Yes    =      7.3 : 1.0\n",
      "         contains(brain) = True               No : Yes    =      6.9 : 1.0\n",
      "          contains(name) = True              Yes : No     =      6.4 : 1.0\n",
      "        contains(rating) = True              Yes : No     =      6.3 : 1.0\n",
      "      contains(computer) = True               No : Yes    =      5.5 : 1.0\n",
      "      contains(property) = True               No : Yes    =      5.2 : 1.0\n",
      "       contains(network) = True               No : Yes    =      5.0 : 1.0\n",
      "       contains(process) = True               No : Yes    =      4.7 : 1.0\n",
      "     contains(frequency) = True              Yes : No     =      4.6 : 1.0\n",
      "    contains(psychology) = True               No : Yes    =      4.6 : 1.0\n",
      "    contains(linguistic) = True               No : Yes    =      4.3 : 1.0\n",
      "    contains(population) = True               No : Yes    =      3.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New data :Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe type is: <class 'pandas.core.frame.DataFrame'>\n",
      "Dataframe shape is: (105, 2)\n",
      "Columns in data frame are: Index(['code', 'Text'], dtype='object')\n",
      "Missing values in Dataframe are: code    0\n",
      "Text    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv('Test_data.csv', encoding='utf-8')\n",
    "df_test1= pd.DataFrame(df_test)\n",
    "print('Dataframe type is:',type(df_test1))\n",
    "print('Dataframe shape is:',df_test1.shape)\n",
    "print('Columns in data frame are:',df_test1.columns)\n",
    "print('Missing values in Dataframe are:',df_test1.isnull().sum())\n",
    "#print(df_test1[:2])\n",
    "\n",
    "\n",
    "df_clean1=df_test1.copy()\n",
    "df_clean1['Text'] = [re.sub('<.*?>', '', e) for e in df_clean1['Text']] #remove HTML tags\n",
    "df_clean1['Text'] =[re.sub(r'[^\\w\\s]', '', e) for e in df_clean1['Text']]## remove punc\n",
    "df_clean1['Text'] =[re.sub(r'\\d+', '', e) for e in df_clean1['Text']]# remove numbers\n",
    "df_clean1['Text']=[re.sub(r'[â€šÃÃº]?', '',e) for e in df_clean1['Text'] ]# remove special character \n",
    "df_clean1['Text']=[re.sub(r'[⁰¹²³⁴⁵⁶⁷⁸⁹]?', '',e) for e in df_clean1['Text'] ]# remove superscript\n",
    "df_clean1['Text']=[re.sub(r'NA', '',e) for e in df_clean1['Text'] ]#remove 'NA' and replace by space\n",
    "df_clean1['Text']=[re.sub(r'Â\\xa0', ' ',e) for e in df_clean1['Text'] ] # remove Â\\xa0\n",
    "df_clean1['Text']=df_clean1['Text'].str.lower() # remove Â\\xa0\n",
    "\n",
    "\n",
    "#print(df_clean1[:1])\n",
    "#print(df_test1[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1746\n",
      "105\n",
      "0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "test_list=df_clean1['Text'].values.tolist()\n",
    "test_token=[word_tokenize(str(x)) for x in test_list]\n",
    "\n",
    "test_list2=df_clean1['code'].values.tolist()\n",
    "test_labeled=list(zip(test_token,test_list2))\n",
    "#print(test_labeled[:2])\n",
    "from random import shuffle \n",
    "shuffle(test_labeled)\n",
    "\n",
    "test_feature = [(document_features(doc), category) for (doc, category) in test_labeled]\n",
    "#print (test_feature)\n",
    "\n",
    "\n",
    "test_list=df_clean1['Text'].values.tolist()\n",
    "test_token=[word_tokenize(str(x)) for x in test_list]\n",
    "\n",
    "test_list2=df_clean1['code'].values.tolist()\n",
    "test_labeled=list(zip(test_token,test_list2))\n",
    "#print(test_labeled[:2])\n",
    "from random import shuffle \n",
    "shuffle(test_labeled)\n",
    "\n",
    "test_feature = [(document_features(doc), category) for (doc, category) in test_labeled]\n",
    "#print (test_feature)\n",
    " \n",
    "test_set = test_feature#new data\n",
    "train_set = train_set#old traning data\n",
    " \n",
    "print (len(train_set)) # Output: \n",
    "print (len(test_set)) # Output: \n",
    " \n",
    "accuracy = classify.accuracy(classifier, test_set)\n",
    "print (accuracy) # Output: 0.365 len feture set 20#output 51% feature 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(biology) = True               No : Yes    =     68.0 : 1.0\n",
      "        contains(health) = True               No : Yes    =     34.7 : 1.0\n",
      "          contains(life) = True               No : Yes    =     22.1 : 1.0\n",
      "   contains(linguistics) = True               No : Yes    =     18.5 : 1.0\n",
      "   contains(familiarity) = True              Yes : No     =     17.3 : 1.0\n",
      "  contains(neuroscience) = True               No : Yes    =     14.1 : 1.0\n",
      "       contains(science) = True               No : Yes    =      9.8 : 1.0\n",
      "        contains(social) = True               No : Yes    =      8.9 : 1.0\n",
      "    contains(researcher) = True               No : Yes    =      7.3 : 1.0\n",
      "         contains(brain) = True               No : Yes    =      6.9 : 1.0\n",
      "          contains(name) = True              Yes : No     =      6.4 : 1.0\n",
      "        contains(rating) = True              Yes : No     =      6.3 : 1.0\n",
      "      contains(computer) = True               No : Yes    =      5.5 : 1.0\n",
      "      contains(property) = True               No : Yes    =      5.2 : 1.0\n",
      "       contains(network) = True               No : Yes    =      5.0 : 1.0\n",
      "       contains(process) = True               No : Yes    =      4.7 : 1.0\n",
      "     contains(frequency) = True              Yes : No     =      4.6 : 1.0\n",
      "    contains(psychology) = True               No : Yes    =      4.6 : 1.0\n",
      "    contains(linguistic) = True               No : Yes    =      4.3 : 1.0\n",
      "    contains(population) = True               No : Yes    =      3.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (classifier.show_most_informative_features(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
