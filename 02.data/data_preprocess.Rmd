---
title: "Data Pre-Processing"
author: "Erin M. Buchanan"
date: "11/5/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE)
```

Script mostly written by Jonathan Korn, updated by EMB.

## Libraries

```{r}
library(readr)
library(tm)
library(stringr)
library(scales)
library(data.table)
library(readtext)
library(taRifx)
```

## [1] - Importing Data...

First, we import the specially coded dataset from EMB with the correct yes/no for all new (2019 and on) and LRE datasets (see below). If you wanted to simply clean new data, you could change the file name here. 

```{r}
fulldata <- read.csv("input_data/completed_clean_data_EMB_code.csv", stringsAsFactors = F)

##only the data we are going to use
small_data <- fulldata[ , c("KEYWORDS", "TITLE", "ABSTRACT", "JOURNAL", "YEAR", "code")]

##put together all text
small_data$text <- paste(small_data$KEYWORDS, small_data$TITLE, small_data$ABSTRACT, sep = " ")

##deal with the yes/no coding
small_data$class <- as.numeric(as.factor(small_data$code))
small_data$class <- ifelse(small_data$class == 1, 0, 1)
table(small_data$class)
```

## [2] - Data Pre-processing...

```{r}
# deal with symbols
small_data$text <- iconv(small_data$text, "latin1", "ASCII", sub = " ")
# deal with keywords starting with keywords
small_data$text <- gsub("^Keywords", " ", small_data$text)
# deal with NA values
small_data$text <- gsub("^NA| NA ", " ", small_data$text)
# lower case
small_data$text <- tolower(small_data$text)
# take out stop words
small_data$text <- removeWords(small_data$text, stopwords(kind = "SMART"))
# take out dashes in a smart way
small_data$text <- gsub("-", " ", small_data$text)
# take out punctuation
small_data$text <- removePunctuation(small_data$text)
# take out numbers
small_data$text <- removeNumbers(small_data$text)
# remove all extra white space
small_data$text <- stripWhitespace(small_data$text)

##write out one here
write.csv(small_data, "output_data/complete_processed_data_no_stem.csv", row.names = F)

##stem the data 
small_data_stem <- small_data
small_data_stem$text <- stemDocument(small_data_stem$text)

write.csv(small_data_stem, "output_data/complete_processed_data_stem.csv", row.names = F)
```

## [3] - Create Datasets

For the purposes of publication and testing/validating the algorithm, we split the data into three subsets:

- Training data: all data from from the LAB including ones we would have found and excluded in our search.
- Testing data - new publications: all data from 2019 and later that would have been searched for new articles (aka information published after the LAB was completed).
- Testing data - LRE: all data from LRE pre-2019 that would be included in new versions of the LAB. This journal was found after the publication of the LAB and was used to validate the algorithm.

The second two datasets were hand marked by EMB for yes/no inclusion for this project to determine the accuracy of the predictive model. 

## Not Stemmed

```{r}
training_data <- subset(small_data, 
                        (JOURNAL != "Computers and the Humanities" & 
                        JOURNAL != "Language Resources and Evaluation" |
                        is.na(JOURNAL)) &
                        (YEAR < 2019 | is.na(YEAR)))

testing_data_new <- subset(small_data,
                           YEAR >= 2019)

testing_data_LRE <- subset(small_data,
                           (JOURNAL == "Computers and the Humanities" | 
                          JOURNAL == "Language Resources and Evaluation") &
                          YEAR < 2019)

nrow(small_data) 
nrow(training_data) #2147
nrow(testing_data_new) #210
nrow(testing_data_LRE) #910

sum(c(nrow(training_data), nrow(testing_data_new), nrow(testing_data_LRE)))

write.csv(training_data, "output_data/training_data_no_stem.csv", row.names = F)
write.csv(testing_data_new, "output_data/test_data_new_no_stem.csv", row.names = F)
write.csv(testing_data_LRE, "output_data/test_data_LRE_no_stem.csv", row.names = F)
```

## Stemmed 

```{r}
training_data <- subset(small_data_stem, 
                        (JOURNAL != "Computers and the Humanities" & 
                        JOURNAL != "Language Resources and Evaluation" |
                        is.na(JOURNAL)) &
                        (YEAR < 2019 | is.na(YEAR)))

testing_data_new <- subset(small_data_stem,
                           YEAR >= 2019)

testing_data_LRE <- subset(small_data_stem,
                           (JOURNAL == "Computers and the Humanities" | 
                          JOURNAL == "Language Resources and Evaluation") &
                          YEAR < 2019)

nrow(small_data_stem) 
nrow(training_data) #2147
nrow(testing_data_new) #210
nrow(testing_data_LRE) #910

sum(c(nrow(training_data), nrow(testing_data_new), nrow(testing_data_LRE)))

write.csv(training_data, "output_data/training_data_stem.csv", row.names = F)
write.csv(testing_data_new, "output_data/test_data_new_stem.csv", row.names = F)
write.csv(testing_data_LRE, "output_data/test_data_LRE_stem.csv", row.names = F)
```

## Yes/No

```{r}
table(training_data$code)

table(testing_data_new$code)

table(testing_data_LRE$code)
```

